# -*- coding: utf-8 -*-
"""PyTorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x3b-heBF00DFRO7puAys0oBRznlgpZqB

## Installing and importing a fastai library of python which is used to run ai model at very fast speed at the time of processing and running all the task
"""

!pip install -Uqq fastai
from fastai.vision.all import *

"""## From the path of URL downloading a datset of various food images which we used further in our model"""

foodpath = untar_data(URLs.FOOD)

img = PILImage.create('/root/.fastai/data/food-101/images/foie_gras/3609374.jpg')
img.show()

"""## now identifying the length of the dataset"""

len(get_image_files(foodpath))

#Use pandas to parse the JSON as a human readable format
pd.read_json('/root/.fastai/data/food-101/train.json')

#Deciding which two foods we want to classify
labelA = 'samosa'
labelB = 'churros'

"""## Data Preprocessing

1. Removing all the unwanted images (images other than labeled one)
2. Renaming images with labeA and labelB to have that label in their filename
"""

#Loop through all Images downloaded
for img in get_image_files(foodpath):
  #Rename images so that the labels(samosa and churros) is in the file name
  if labelA in str(img):
    img.rename(f"{img.parent}/{labelA}_{img.name}")
  elif labelB in str(img):
    img.rename(f"{img.parent}/{labelB}_{img.name}")
  else: os.remove(img) #If images are not part of labels A and B , just remove it


len(get_image_files(foodpath))

"""## Train Model"""

def GetLabel(fileName):
  return fileName.split('_')[0]


GetLabel("churros_734186.jpg") #testing

dls = ImageDataLoaders.from_name_func(
    foodpath, get_image_files(foodpath), valid_pct=0.2, seed=420,
    label_func=GetLabel, item_tfms=Resize(224))

dls.valid.show_batch()

learn = cnn_learner(dls , resnet34 , metrics=error_rate , pretrained = True)
learn.fine_tune(epochs=10)

"""## Verify Model"""

# Upload your own images
from google.colab import files
uploader  = files.upload()

for img in uploader.items():
  uploadedImg = img[0]

img = PILImage.create(uploadedImg)
img.show()

label,_,probs = learn.predict(img)

print(f"This is a {label}.")
print(f"{labelA} {probs[1].item():.6f}")
print(f"{labelB} {probs[0].item():.6f}")

"""## Confusion matrix"""

interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix(figsize=(5,5))
interp.plot_top_losses(6)

"""## Deploy"""



learn.export() #exorts model as 'export.pkl' by default

# let's get the first pkl file we can find
modelPath = get_files(foodpath, '.pkl') [0]
modelPath

# !pip install matplotlib
# import matplotlib.image as mpimg # import the required module

learn_inf = load_learner(modelPath)
learn_inf.predict(mpimg.imread(get_image_files(foodpath)[0])) #raw prediction

learn_inf.dls.vocab  #get the labels

from google.colab import files
files.download(modelPath)

